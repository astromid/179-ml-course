{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit ('nn179': conda)",
   "metadata": {
    "interpreter": {
     "hash": "b535a82a3b9259ae693695d68fa86b08ae8b3bec72aa6a0359cf505f9926a8ce"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# вместо обычной LinearRegression будем использовать Ridge - более устойчивая модификация линейной регрессии\n",
    "# для нормализации признаков используйте Ridge с параметром normalize=True\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# визуализация коэффициентов линейной регрессии\n",
    "def visualize_coefficients(coefs, feature_names, top_n):\n",
    "    \"\"\"\n",
    "    Функция для визуализации коэффициентов линейной регрессии.\n",
    "\n",
    "    Параметры:\n",
    "    -----------\n",
    "        coefs: коэффициенты модели (model.coef_)\n",
    "        feature_names: названия признаков (X_train.columns)\n",
    "        top_n: вывести top_n самых положительных и top_n самых отрицательных признаков\n",
    "    \"\"\"\n",
    "    feature_names = np.array(feature_names)\n",
    "    if top_n * 2 > len(coefs):\n",
    "        n_pos = len(coefs) // 2\n",
    "        n_neg = len(coefs) - n_pos\n",
    "    else:\n",
    "        n_pos, n_neg = top_n, top_n\n",
    "    # нам нужно найти индексы top_n наибольших и top_n наименьших коэффициентов\n",
    "    min_coef_idxs = np.argsort(coefs)[:n_neg]\n",
    "    max_coef_idxs = np.argsort(coefs)[len(coefs) - n_pos:]\n",
    "    # соответствующие имена фичей\n",
    "    top_feature_names = np.concatenate((feature_names[min_coef_idxs], feature_names[max_coef_idxs])) \n",
    "    # отобразим на bar-графике\n",
    "    fig, ax = plt.subplots(figsize=(16, 9))\n",
    "    ax.bar(np.arange(n_neg), coefs[min_coef_idxs], color=sns.xkcd_rgb['mauve'], hatch='/')\n",
    "    ax.bar(np.arange(n_neg, n_neg + n_pos), coefs[max_coef_idxs], color=sns.xkcd_rgb['teal'], hatch='\\\\')\n",
    "    ax.set_xticks(np.arange(0, n_neg + n_pos))\n",
    "    ax.set_xticklabels(top_feature_names, rotation=45, ha=\"right\", fontsize=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('indian-metro.csv', parse_dates=['date_time'], index_col='date_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# вы можете проверить, что признак dew_point - это копия признака visibility_in_miles\n",
    "# поэтому его нужно удалить - линейные модели болеют от наличия абсолютно одинаковых признаков в датасете\n",
    "df = df.drop('dew_point', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выделим последний год в тестовую выборку, и еще один год в валидационную\n",
    "test_start = df.index.max() - pd.Timedelta('1y')\n",
    "val_start = test_start - pd.Timedelta('1y')\n",
    "\n",
    "print(f'Test start date: {test_start}')\n",
    "print(f'Validation start date: {val_start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# в дальшейшем вы можете разбить свою выборку, выполнив\n",
    "# train = df[df.index < val_start]\n",
    "# val = df[(df.index >= val_start) & (df.index < test_start)]\n",
    "# test = df[df.index >= test_start]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, val_start, test_start):\n",
    "    train = df[df.index < val_start]\n",
    "    val = df[(df.index >= val_start) & (df.index < test_start)]\n",
    "    test = df[df.index >= test_start]\n",
    "\n",
    "    const_cols = train.columns[train.nunique() == 1]\n",
    "    train = train.drop(const_cols, axis=1)\n",
    "    val = val.drop(const_cols, axis=1)\n",
    "    test = test.drop(const_cols, axis=1)\n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ridge(train, val):\n",
    "    y_train = train['traffic_volume']\n",
    "    X_train = train.drop('traffic_volume', axis=1)\n",
    "\n",
    "    y_val = val['traffic_volume']\n",
    "    X_val = val.drop('traffic_volume', axis=1)\n",
    "\n",
    "    model = Ridge(normalize=True)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    mse = mean_squared_error(y_val, y_pred)\n",
    "    return model, mse, y_pred, X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_preds(y_true, y_pred, n_hours=336):\n",
    "    fig, ax = plt.subplots(figsize=(21, 9))\n",
    "    index = y_true[-n_hours:].index\n",
    "    ax.plot(index, y_true[-n_hours:], label='y_true')\n",
    "    ax.plot(index, y_pred[-n_hours:], label='y_pred')\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "source": [
    "## Elementary level: 35%"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "*Задание*\n",
    "\n",
    "*1. Удалите все нечисловные признаки из датасета*\n",
    "\n",
    "*2. Выделите из выборки трейн и валидацию, не забудьте о масштабировании (нормализации) признаков*\n",
    "\n",
    "*3. Обучите линейную регрессию на трейне, посчитайте MSE на валидации*\n",
    "\n",
    "*4. Визуализируйте коэффициенты и предсказания. Для визуализации прогнозов возьмите, например, две последние недели в валидации*\n",
    "\n",
    "*Замечание: после того, как вы разделите выборку может оказаться так, что в трейне некоторые признаки принимают константное значение. Их нужно удалить*\n",
    "\n",
    "*Подсказка: для проверки количества уникальных значений в столбцах можно использовать df.nunique().sort_values()*"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def level1_preprocessing(df):\n",
    "    df = df.copy()\n",
    "    df = df.drop(['is_holiday', 'weather_type', 'weather_description'], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level1_df = level1_preprocessing(df)\n",
    "level1_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, _ = split_data(level1_df, val_start, test_start)\n",
    "model, val_mse, val_preds, feature_names = train_ridge(train, val)\n",
    "print(f'Validation RMSE: {np.sqrt(val_mse)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_coefficients(model.coef_, feature_names, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_preds(val['traffic_volume'], val_preds)"
   ]
  },
  {
   "source": [
    "## Pre-intermediate: 25%"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "*Если вы построите график целевой переменной, то увидите ее сильную зависимость от даты*\n",
    "\n",
    "*Создайте новые признаки года, месяца, дня и часа с помощью df.index.year, df.index.month и.т.п и проверьте качество на валидации*\n",
    "\n",
    "*Не забудьте визуализировать предсказания и коэффициенты*"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def level2_preprocessing(df):\n",
    "    df = df.copy()\n",
    "    df = level1_preprocessing(df)\n",
    "    df['year'] = df.index.year\n",
    "    df['month'] = df.index.month\n",
    "    df['day'] = df.index.day\n",
    "    df['hour'] = df.index.hour\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level2_df = level2_preprocessing(df.copy())\n",
    "train, val, _ = split_data(level2_df, val_start, test_start)\n",
    "model, val_mse, val_preds, feature_names = train_ridge(train, val)\n",
    "print(f'Validation RMSE: {np.sqrt(val_mse)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_coefficients(model.coef_, feature_names, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_preds(val['traffic_volume'], val_preds)"
   ]
  },
  {
   "source": [
    "## Intermediate: 20%"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "*Попробуйте закодировать отброшенные ранее категориальные признаки с помощью pd.get_dummies*\n",
    "\n",
    "*Посмотрите на скор на валидации, визуализируйте результаты*\n",
    "\n",
    "*Замечание: применять pd.get_dummies нужно до разделения на трейн/вал/тест, чтобы функция видела все значения категорий*\n",
    "\n",
    "*Подсказка: к колонке weather_description лучше сначала применить .str.lower() - подумайте почему :)*"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def level3_preprocessing(df):\n",
    "    df = df.copy()\n",
    "    level2_df = level2_preprocessing(df)\n",
    "\n",
    "    df['weather_description'] = df['weather_description'].str.lower()\n",
    "    dummies = pd.get_dummies(df[['is_holiday', 'weather_type', 'weather_description']])\n",
    "    return pd.concat([level2_df, dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level3_df = level3_preprocessing(df)\n",
    "level3_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, _ = split_data(level3_df, val_start, test_start)\n",
    "model, val_mse, val_preds, feature_names = train_ridge(train, val)\n",
    "print(f'Validation RMSE: {np.sqrt(val_mse)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_coefficients(model.coef_, feature_names, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_preds(val['traffic_volume'], val_preds)"
   ]
  },
  {
   "source": [
    "## Upper-intermediate: 20%"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "*На семинаре мы обсудили, что предыдущее значение целевой переменной может сильно помочь в предсказании временного ряда*\n",
    "\n",
    "*Добавьте с помощью метода .shift() к колонкам сколько-то предыдущих значений целевой переменной, сколько конкретно - подберите на валидации*\n",
    "\n",
    "*Визуализируйте прогнозы и коэффициенты модели*"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lags(df, n_lags):\n",
    "    df = df.copy()\n",
    "    for lag_idx in range(1, n_lags + 1):\n",
    "        df[f'lag_{lag_idx}'] = df['traffic_volume'].shift(lag_idx)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "lag_mses = []\n",
    "for n_lags in tqdm(range(400)):\n",
    "    lagged_df = add_lags(level3_df, n_lags=n_lags)\n",
    "    train, val, _ = split_data(lagged_df, val_start, test_start)\n",
    "    train = train.dropna()\n",
    "    _, val_mse, _, _ = train_ridge(train, val)\n",
    "    lag_mses.append(np.sqrt(val_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "ax.plot(range(400), lag_mses)\n",
    "ax.set_title(f'Best val_rsme = {min(lag_mses)} at {np.argmin(lag_mses)} lags')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# будем использовать 8 лагов\n",
    "def level4_preprocessing(df):\n",
    "    df = df.copy()\n",
    "    df = level3_preprocessing(df)\n",
    "    df = add_lags(df, n_lags=8)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level4_df = level4_preprocessing(df)\n",
    "train, val, _ = split_data(level4_df, val_start, test_start)\n",
    "train = train.dropna()\n",
    "model, val_mse, val_preds, feature_names = train_ridge(train, val)\n",
    "print(f'Validation RMSE: {np.sqrt(val_mse)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_coefficients(model.coef_, feature_names, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_preds(val['traffic_volume'], val_preds)"
   ]
  },
  {
   "source": [
    "## Advanced"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_preds(val['traffic_volume'], val_preds, n_hours=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "level4_df.groupby('hour')['traffic_volume'].mean().plot(kind='bar', ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def level5_preprocessing(df):\n",
    "    df = df.copy()\n",
    "    df = level4_preprocessing(df)\n",
    "    df['is_night'] = df['hour'].apply(lambda x: 0 <= x <= 4)\n",
    "    df['is_morning_peak'] = df['hour'].apply(lambda x: 6 <= x <= 8)\n",
    "    df['is_evening_peak'] = df['hour'].apply(lambda x: 15 <= x <= 17)\n",
    "    df['weekday'] = df.index.weekday\n",
    "    df['weekend'] = df['weekday'].apply(lambda x: x in (5, 6))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level5_df = level5_preprocessing(df)\n",
    "train, val, _ = split_data(level5_df, val_start, test_start)\n",
    "train = train.dropna()\n",
    "model, val_mse, val_preds, feature_names = train_ridge(train, val)\n",
    "print(f'Validation RMSE: {np.sqrt(val_mse)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_coefficients(model.coef_, feature_names, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_preds(val['traffic_volume'], val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_preds(val['traffic_volume'], val_preds, n_hours=36)"
   ]
  },
  {
   "source": [
    "## Mastery"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weather_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def level6_preprocessing(df):\n",
    "    df = df.copy()\n",
    "    df = level5_preprocessing(df)\n",
    "    df['cos_hour'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
    "    df['sin_hour'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
    "    \n",
    "    df['cos_weekday'] = np.cos(2 * np.pi * df['weekday'] / 7)\n",
    "    df['sin_weekday'] = np.sin(2 * np.pi * df['weekday'] / 7)\n",
    "    \n",
    "    df['cos_month'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "    df['sin_month'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "    \n",
    "    df['cos_wind_direction'] = np.cos(2 * np.pi * df['wind_direction'] / 360)\n",
    "    df['sin_wind_direction'] = np.sin(2 * np.pi * df['wind_direction'] / 360)\n",
    "    \n",
    "    df['is_holiday'] = ~df['is_holiday_None'].astype('bool')\n",
    "    df = df.drop('is_holiday_None', axis=1)\n",
    "    df['not_bad_weather'] = df['weather_type_Clear'] | df['weather_type_Clouds']\n",
    "    df['bad_weather'] = df['weather_type_Rain'] | df['weather_type_Snow'] | df['weather_type_Thunderstorm'] | df['weather_type_Squall']\n",
    "    df['doubtful_weather'] = df['weather_type_Mist'] | df['weather_type_Drizzle'] | df['weather_type_Haze'] | df['weather_type_Fog']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level6_df = level6_preprocessing(df)\n",
    "train, val, _ = split_data(level6_df, val_start, test_start)\n",
    "train = train.dropna()\n",
    "model, val_mse, val_preds, feature_names = train_ridge(train, val)\n",
    "print(f'Validation RMSE: {np.sqrt(val_mse)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_coefficients(model.coef_, feature_names, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_preds(val['traffic_volume'], val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_preds(val['traffic_volume'], val_preds, n_hours=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = split_data(level6_df, val_start, test_start)\n",
    "train = train.dropna()\n",
    "train = pd.concat([train, val], axis=0)\n",
    "model, test_mse, test_preds, feature_names = train_ridge(train, test)\n",
    "print(f'Test RMSE: {np.sqrt(test_mse)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_preds(test['traffic_volume'], test_preds)"
   ]
  }
 ]
}