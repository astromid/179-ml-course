{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit ('nn179': conda)",
   "metadata": {
    "interpreter": {
     "hash": "b535a82a3b9259ae693695d68fa86b08ae8b3bec72aa6a0359cf505f9926a8ce"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# вместо обычной LinearRegression будем использовать Ridge - более устойчивая модификация линейной регрессии\n",
    "# для нормализации признаков используйте Ridge с параметром normalize=True\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# визуализация коэффициентов линейной регрессии\n",
    "def visualize_coefficients(coefs, feature_names, top_n):\n",
    "    \"\"\"\n",
    "    Функция для визуализации коэффициентов линейной регрессии.\n",
    "\n",
    "    Параметры:\n",
    "    -----------\n",
    "        coefs: коэффициенты модели (model.coef_)\n",
    "        feature_names: названия признаков (X_train.columns)\n",
    "        top_n: вывести top_n самых положительных и top_n самых отрицательных признаков\n",
    "    \"\"\"\n",
    "    feature_names = np.array(feature_names)\n",
    "    if top_n * 2 > len(coefs):\n",
    "        n_pos = len(coefs) // 2\n",
    "        n_neg = len(coefs) - n_pos\n",
    "    else:\n",
    "        n_pos, n_neg = top_n, top_n\n",
    "    # нам нужно найти индексы top_n наибольших и top_n наименьших коэффициентов\n",
    "    min_coef_idxs = np.argsort(coefs)[:n_neg]\n",
    "    max_coef_idxs = np.argsort(coefs)[len(coefs) - n_pos:]\n",
    "    # соответствующие имена фичей\n",
    "    top_feature_names = np.concatenate((feature_names[min_coef_idxs], feature_names[max_coef_idxs])) \n",
    "    # отобразим на bar-графике\n",
    "    fig, ax = plt.subplots(figsize=(16, 9))\n",
    "    ax.bar(np.arange(n_neg), coefs[min_coef_idxs], color=sns.xkcd_rgb['mauve'], hatch='/')\n",
    "    ax.bar(np.arange(n_neg, n_neg + n_pos), coefs[max_coef_idxs], color=sns.xkcd_rgb['teal'], hatch='\\\\')\n",
    "    ax.set_xticks(np.arange(0, n_neg + n_pos))\n",
    "    ax.set_xticklabels(top_feature_names, rotation=45, ha=\"right\", fontsize=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('indian-metro.csv', parse_dates=['date_time'], index_col='date_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# вы можете проверить, что признак dew_point - это копия признака visibility_in_miles\n",
    "# поэтому его нужно удалить - линейные модели болеют от наличия абсолютно одинаковых признаков в датасете\n",
    "df = df.drop('dew_point', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выделим последний год в тестовую выборку, и еще один год в валидационную\n",
    "test_start = df.index.max() - pd.Timedelta('1y')\n",
    "val_start = test_start - pd.Timedelta('1y')\n",
    "\n",
    "print(f'Test start date: {test_start}')\n",
    "print(f'Validation start date: {val_start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# в дальшейшем вы можете разбить свою выборку, выполнив\n",
    "# train = df[df.index < val_start]\n",
    "# val = df[(df.index >= val_start) & (df.index < test_start)]\n",
    "# test = df[df.index >= test_start]"
   ]
  },
  {
   "source": [
    "## Elementary level: 35%"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "*Задание*\n",
    "\n",
    "*1. Удалите все нечисловные признаки из датасета*\n",
    "\n",
    "*2. Выделите из выборки трейн и валидацию, не забудьте о масштабировании (нормализации) признаков*\n",
    "\n",
    "*3. Обучите линейную регрессию на трейне, посчитайте MSE на валидации*\n",
    "\n",
    "*4. Визуализируйте коэффициенты и предсказания. Для визуализации прогнозов возьмите, например, две последние недели в валидации*\n",
    "\n",
    "*Замечание: после того, как вы разделите выборку может оказаться так, что в трейне некоторые признаки принимают константное значение. Их нужно удалить*\n",
    "\n",
    "*Подсказка: для проверки количества уникальных значений в столбцах можно использовать df.nunique().sort_values()*"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?pd.DataFrame.nunique"
   ]
  },
  {
   "source": [
    "## Pre-intermediate: 25%"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "*Если вы построите график целевой переменной, то увидите ее сильную зависимость от даты*\n",
    "\n",
    "*Создайте новые признаки года, месяца, дня и часа с помощью df.index.year, df.index.month и.т.п и проверьте качество на валидации*\n",
    "\n",
    "*Не забудьте визуализировать предсказания и коэффициенты*"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Intermediate: 20%"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "*Попробуйте закодировать отброшенные ранее категориальные признаки с помощью pd.get_dummies*\n",
    "\n",
    "*Посмотрите на скор на валидации, визуализируйте результаты*\n",
    "\n",
    "*Замечание: применять pd.get_dummies нужно до разделения на трейн/вал/тест, чтобы функция видела все значения категорий*\n",
    "\n",
    "*Подсказка: к колонке weather_description лучше сначала применить .str.lower() - подумайте почему :)*"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?pd.get_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?pd.Series.str.lower"
   ]
  },
  {
   "source": [
    "## Upper-intermediate: 20%"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "*На семинаре мы обсудили, что предыдущее значение целевой переменной может сильно помочь в предсказании временного ряда*\n",
    "\n",
    "*Добавьте с помощью метода .shift() к колонкам сколько-то предыдущих значений целевой переменной, сколько конкретно - подберите на валидации*\n",
    "\n",
    "*Визуализируйте прогнозы и коэффициенты модели*"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?pd.Series.shift"
   ]
  }
 ]
}