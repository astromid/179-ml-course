{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPq3fr6nlXhnmxOiDNgViBC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Семинар по линейной классификации"],"metadata":{"id":"ZzPlKYgHPbdd"}},{"cell_type":"markdown","source":["В этом семинаре мы научимся решать задачи классификации с помощью линейной модели из scikit-learn."],"metadata":{"id":"NOjZ2Ib2PgPN"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"1XKp-j1YPLwP"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","sns.set()"]},{"cell_type":"markdown","source":["Работать будем с очень известным в мат.статистике набором данных - \"Ирисы Фишера\": https://ru.wikipedia.org/wiki/%D0%98%D1%80%D0%B8%D1%81%D1%8B_%D0%A4%D0%B8%D1%88%D0%B5%D1%80%D0%B0\n","\n","Этот датасет содержит в себе три класса. На лекциях мы пока разбирали только случай бинарной классификации, но все наши определения можно обобщить и на многоклассовый случай (на следующей лекции немного уделим этому время)."],"metadata":{"id":"_5ZI5e1Wq21t"}},{"cell_type":"code","source":["# датасет доступен сразу из sklearn\n","from sklearn.datasets import load_iris\n","\n","data, target = load_iris(return_X_y=True, as_frame=True)"],"metadata":{"id":"YtdzvoeaPxTb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data.head()"],"metadata":{"id":"H6N1NaEYr0sk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data.info()"],"metadata":{"id":"t6uO-Nvrr1Rs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["target.value_counts()"],"metadata":{"id":"cOLuX16fr4oj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Каждый ирис описывается 4-мя численными признаками и отнесен к одному из 3-х классов.\n","\n","Разобьём данные на обучение и тест:"],"metadata":{"id":"oVNl_GOyr_P-"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.25, stratify=target, random_state=14300631)"],"metadata":{"id":"sN3_mcbbr550"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Для предсказания класса ириса используем модель \"Логистическая регрессия\" (это линейный классификатор, почему он так называется - доразберем на лекции)"],"metadata":{"id":"q3eBkgbLtZAR"}},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\n","\n","clf = LogisticRegression()\n","clf.fit(X_train, y_train)"],"metadata":{"id":"6gLcdl4stWUn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Посчитае метрики, которые мы ранее обсуждали: долю правильных ответов, точность, полноту, F-меру\n","\n","*В вызове функций появился какой-то параметр \"macro\". Попробуйте разобраться с помощью документации, что он означает? И почему для accuracy_score его нет?*"],"metadata":{"id":"S_YIEFfut0bk"}},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","y_pred_train = clf.predict(X_train)\n","y_pred_test = clf.predict(X_test)\n","\n","print(\"Метрики на трейне\")\n","print(\"-\" * 20)\n","print(f\"Accuracy: {accuracy_score(y_train, y_pred_train)}\")\n","print(f\"Precision: {precision_score(y_train, y_pred_train, average='macro')}\")\n","print(f\"Recall: {recall_score(y_train, y_pred_train, average='macro')}\")\n","print(f\"F1: {f1_score(y_train, y_pred_train, average='macro')}\")\n","print(\"-\" * 20)\n","print(\"\\n\")\n","print(\"Метрики на тесте\")\n","print(\"-\" * 20)\n","print(f\"Accuracy: {accuracy_score(y_test, y_pred_test)}\")\n","print(f\"Precision: {precision_score(y_test, y_pred_test, average='macro')}\")\n","print(f\"Recall: {recall_score(y_test, y_pred_test, average='macro')}\")\n","print(f\"F1: {f1_score(y_test, y_pred_test, average='macro')}\")"],"metadata":{"id":"xL6vmLdvtvyC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Видно, что предсказывается очень неплохо :)\n","\n","Сразу получить набор метрик можно с помощью функции classification_report:"],"metadata":{"id":"bWZPWd5cvCDF"}},{"cell_type":"code","source":["from sklearn.metrics import classification_report\n","\n","print(classification_report(y_test, y_pred_test))"],"metadata":{"id":"V15_pyf2uw37"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Заодно отобразим матрицу ошибок:"],"metadata":{"id":"V9f2ILu_xO92"}},{"cell_type":"code","source":["from sklearn.metrics import ConfusionMatrixDisplay\n","\n","cm = ConfusionMatrixDisplay.from_predictions(y_test, y_pred_test, cmap=plt.cm.Blues)\n","cm.ax_.grid(False)  # отключаем координатную сетку"],"metadata":{"id":"0Fa5Szm9xKBy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Домашнее задание"],"metadata":{"id":"xNCeNdvSyx1H"}},{"cell_type":"markdown","source":["Попытаемся предсказывать \"опасность\" различных астероидов для Земли, основываясь на наборе данных от NASA. Каждый астероид описывается набором признаков (подробное описание датасета можно посмотреть тут: https://www.kaggle.com/datasets/shrutimehta/nasa-asteroids-classification) и целевой переменной \"Hazardous\". Таким образом, задача является бинарной классификацией."],"metadata":{"id":"bXwXZ1MYy0hi"}},{"cell_type":"markdown","source":["Ссылка на датасет (GDrive): https://drive.google.com/file/d/13_Ko3rmiE6s-Hx34sQ7jtF3BNt08hTjN/view?usp=share_link"],"metadata":{"id":"yIO7qLjg18Mv"}},{"cell_type":"markdown","source":["Задание:\n","\n","1.   Разбить выборку на обучение/валидацию/тест (0.7/0.2/0.1). Датасет не сбалансированный, поэтому не забудьте про параметр `stratify`. Для воспроизводимости экспериментов используйте параметр `random_state=179`.\n","2.   Работа с признаками: нужно подумать, какие признаки полезные, какие нет, можно ли на основе имеющихся данных придумать какие-то новые полезные для модели признаки, каким образом лучше закодировать имеющиеся признаки. Проводя эксперименты, обучайте модель на train и следите за метрикой F1 на валидации. Не забудьте про важность нормирования признаков с помощью `MinMaxScaler` или `StandardScaler`.\n","3. *Опционально: можете также поэкспериментировать с гиперпараметрами самой модели `LogisticRegression`, основываясь на документации.*\n","4. Для вашего лучшего эксперимента из пунктов 2 и 3 обучите модель совместно на данных train + val и посчитайте все метрики на тестовой части.\n","5. Попробуйте заменить модель логистической регрессии на обычную линейную регрессию. Станет ли качество модели хуже?\n","\n","\n","\n"],"metadata":{"id":"aMVqUVs0zZUw"}},{"cell_type":"code","source":[],"metadata":{"id":"_RGpjV74xA1u"},"execution_count":null,"outputs":[]}]}