{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDQV0x58d3SJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "# вместо LinearRegression будем использовать Ridge\n",
        "# это численно более стабильная модификация обычной линейной регрессии\n",
        "from sklearn.linear_model import Ridge\n",
        "# измерять качество предсказаний будем с помощью стандартной MSE\n",
        "from sklearn.metrics import mean_squared_error\n",
        "# для нормализации данных будем использовать MinMixScaler\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_coefficients(coefs, feature_names, top_n):\n",
        "    \"\"\"Функция для визуализации коэффициентов линейной регрессии.\n",
        "\n",
        "    Параметры:\n",
        "        coefs: коэффициенты модели (model.coef_).\n",
        "        feature_names: названия признаков (X_train.columns).\n",
        "        top_n: вывести top_n самых положительных и top_n самых отрицательных признаков.\n",
        "    \"\"\"\n",
        "    feature_names = np.array(feature_names)\n",
        "    if top_n * 2 > len(coefs):\n",
        "        n_pos = len(coefs) // 2\n",
        "        n_neg = len(coefs) - n_pos\n",
        "    else:\n",
        "        n_pos, n_neg = top_n, top_n\n",
        "    # нам нужно найти индексы top_n наибольших и top_n наименьших коэффициентов\n",
        "    min_coef_idxs = np.argsort(coefs)[:n_neg]\n",
        "    max_coef_idxs = np.argsort(coefs)[len(coefs) - n_pos:]\n",
        "    # соответствующие имена фичей\n",
        "    top_feature_names = np.concatenate((feature_names[min_coef_idxs], feature_names[max_coef_idxs])) \n",
        "    # отобразим на bar-графике\n",
        "    fig, ax = plt.subplots(figsize=(16, 9))\n",
        "    ax.bar(np.arange(n_neg), coefs[min_coef_idxs], color=sns.xkcd_rgb[\"mauve\"], hatch=\"/\")\n",
        "    ax.bar(np.arange(n_neg, n_neg + n_pos), coefs[max_coef_idxs], color=sns.xkcd_rgb[\"teal\"], hatch=\"\\\\\")\n",
        "    ax.set_xticks(np.arange(0, n_neg + n_pos))\n",
        "    ax.set_xticklabels(top_feature_names, rotation=45, ha=\"right\", fontsize=14)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Ek_Z1d8sgwQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_preds(y_true, y_pred, n_hours=336):\n",
        "    \"\"\"Функция для визуализации таргета и предсказаний.\n",
        "\n",
        "    Параметры:\n",
        "        y_true: правильные ответы.\n",
        "        y_pred: предсказания модели.\n",
        "        n_hours: вывести на график заданное число точек с конца. По умолчанию 2 недели.\n",
        "\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(21, 9))\n",
        "    index = y_true[-n_hours:].index\n",
        "    ax.plot(index, y_true[-n_hours:], label=\"y_true\")\n",
        "    ax.plot(index, y_pred[-n_hours:], label=\"y_pred\")\n",
        "    ax.legend()\n",
        "\n",
        "    delta_len = len(y_true) - len(y_pred)\n",
        "    val_mse = mean_squared_error(y_true[delta_len:], y_pred)\n",
        "    ax.set_title(f\"Validation MSE: {val_mse}\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "krjFdPL5g48q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Загрузка данных"
      ],
      "metadata": {
        "id": "prn1-VfzwZQy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# parse_dates позволяет сразу распарсить даты в данных\n",
        "# с помощью index_col указываем что будем использовать колонку с датой в качестве индекса датафрейма\n",
        "train_df = pd.read_csv(\"indian-metro-train.csv\", parse_dates=[\"date_time\"], index_col=\"date_time\")\n",
        "val_df = pd.read_csv(\"indian-metro-val.csv\", parse_dates=[\"date_time\"], index_col=\"date_time\")"
      ],
      "metadata": {
        "id": "oZ48KqCLePYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "id": "N4fe09cVnmZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_df.head()"
      ],
      "metadata": {
        "id": "87h8xMp9u7XU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Как видно, датафрейм содержит измерения количества людей в метро. Для каждого измерения доступна его дата и время (с разрешением до часа), а также набор признаков, описывающих ситуацию на момент измерения:\n",
        "\n",
        "\n",
        "*   is_holiday: название праздника, если он проводится в этот день\n",
        "*   air_pollution_index: индекс качества воздуха\n",
        "*   humidity: относительная влажность в градусах Цельсия\n",
        "*   wind_speed: скорость ветра в миль/ч\n",
        "*   wind_direction: направление ветра в градусах\n",
        "*   visibility_in_miles: видимость в милях\n",
        "*   temperature: температура в Кельвинах\n",
        "*   rain_p_h: количество выпавших осадков в мм за час\n",
        "*   clouds_all\n",
        "*   weather_type\n",
        "*   weather_description: \n",
        "*   traffic_volume: количество людей, целевая переменная\n",
        "\n"
      ],
      "metadata": {
        "id": "6Kbthw71weG_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Будем решать задачу предсказания traffic_volume по остальным признакам. Оценивать качество будем с помощью MSE на валидационной выборке. На семинаре также оценим ваши лучшие модели на отдельной тестовой выборке."
      ],
      "metadata": {
        "id": "sQ9lSqTwydwJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trainee"
      ],
      "metadata": {
        "id": "LTqXVrDYyqSG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Попробуем обучить самую простую модель. Датасет содержит 3 нечисловых признака, с которыми придется отдельно придумать, что делать, поэтому просто исключим их (не забыв исключить и целевую переменную):"
      ],
      "metadata": {
        "id": "w11NPd09yvs0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# рекомендую оформлять свой код подготовки данных в функции похожего вида\n",
        "def prepare_data_trainee(train_df, val_df):\n",
        "    X_train = train_df.drop([\"is_holiday\", \"weather_type\", \"weather_description\", \"traffic_volume\"], axis=1)\n",
        "    X_val = val_df.drop([\"is_holiday\", \"weather_type\", \"weather_description\", \"traffic_volume\"], axis=1)\n",
        "    # сохраним названия признаков для отрисовки графика\n",
        "    feature_names = X_train.columns.tolist()\n",
        "\n",
        "    y_train = train_df[\"traffic_volume\"]\n",
        "    y_val = val_df[\"traffic_volume\"]\n",
        "\n",
        "    # нормализуем данные для линейной регрессии\n",
        "    scl = MinMaxScaler()\n",
        "    X_train = scl.fit_transform(X_train)\n",
        "    # !Важно: для train применяем метод .fit_transform(), для валидации и/или тест - .transform()\n",
        "    X_val = scl.transform(X_val)\n",
        "    return X_train, y_train, X_val, y_val, feature_names"
      ],
      "metadata": {
        "id": "zgqvTGttwIZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_ridge(train_df, val_df, prepare_func, alpha=1.0):\n",
        "    X_train, y_train, X_val, y_val, feature_names = prepare_func(train_df, val_df)\n",
        "    model = Ridge(alpha=alpha, random_state=14300631)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    train_predictions = model.predict(X_train)\n",
        "    val_predictions = model.predict(X_val)\n",
        "\n",
        "    train_mse = mean_squared_error(y_train, train_predictions)\n",
        "    val_mse = mean_squared_error(y_val, val_predictions)\n",
        "\n",
        "    print(f\"Train MSE: {train_mse}\")\n",
        "    print(f\"Validation MSE: {val_mse}\")\n",
        "    return {\n",
        "        \"model\": model,\n",
        "        \"train_preds\": train_predictions,\n",
        "        \"val_preds\": val_predictions,\n",
        "        \"features\": feature_names,\n",
        "    }"
      ],
      "metadata": {
        "id": "KXr0hRmbUfKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_trainee = fit_ridge(train_df, val_df, prepare_data_trainee)"
      ],
      "metadata": {
        "id": "ow_W0B1o11gv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модель успешно обучилась. Большой разницы между ошибкой на обучении и валидации не видно, значит как минимум модель пока что не переобучается :)\n",
        "\n",
        "Давайте посмотрим как выглядит целевая переменная и предсказании на графике:"
      ],
      "metadata": {
        "id": "KRP279wa2k9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_preds(val_df[\"traffic_volume\"], result_trainee[\"val_preds\"])"
      ],
      "metadata": {
        "id": "19tNFYOE2keV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модель явно слишком слабая - ей не хватает признаков, чтобы ухватить зависимость сложнее, чем предсказание около среднего.\n",
        "\n",
        "Посмотрим также на влияние признаков:"
      ],
      "metadata": {
        "id": "vWki1XQ-3Day"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_coefficients(result_trainee[\"model\"].coef_, result_trainee[\"features\"], 15)"
      ],
      "metadata": {
        "id": "2weqg_bF2Uew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Забавно. Чем выше температура на улице - тем больше людей в метро по мнению модели, а чем больше осадков выпадало - тем меньше :)"
      ],
      "metadata": {
        "id": "ErBbMo_I4qHC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Junior"
      ],
      "metadata": {
        "id": "CMrgS81I5Uhd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_time_features(df):\n",
        "    df[\"year\"] = df.index.year\n",
        "    df[\"month\"] = df.index.month\n",
        "    df[\"day\"] = df.index.day\n",
        "    df[\"hour\"] = df.index.hour\n",
        "    return df\n",
        "\n",
        "\n",
        "def prepare_data_junior(train_df, val_df):\n",
        "    X_train = train_df.drop([\"is_holiday\", \"weather_type\", \"weather_description\", \"traffic_volume\"], axis=1)\n",
        "    X_val = val_df.drop([\"is_holiday\", \"weather_type\", \"weather_description\", \"traffic_volume\"], axis=1)\n",
        "\n",
        "    # добавляем временные признаки\n",
        "    X_train = add_time_features(X_train)\n",
        "    X_val = add_time_features(X_val)\n",
        "    # сохраним названия признаков для отрисовки графика\n",
        "    feature_names = X_train.columns.tolist()\n",
        "\n",
        "    y_train = train_df[\"traffic_volume\"]\n",
        "    y_val = val_df[\"traffic_volume\"]\n",
        "\n",
        "    # нормализуем данные для линейной регрессии\n",
        "    scl = MinMaxScaler()\n",
        "    X_train = scl.fit_transform(X_train)\n",
        "    # !Важно: для train применяем метод .fit_transform(), для валидации и/или тест - .transform()\n",
        "    X_val = scl.transform(X_val)\n",
        "    return X_train, y_train, X_val, y_val, feature_names"
      ],
      "metadata": {
        "id": "s0EsYtte6zDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_junior = fit_ridge(train_df, val_df, prepare_data_junior)"
      ],
      "metadata": {
        "id": "f36dczT-UZsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_preds(val_df[\"traffic_volume\"], result_junior[\"val_preds\"])"
      ],
      "metadata": {
        "id": "HJKDxEHuX8Mv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_coefficients(result_junior[\"model\"].coef_, result_junior[\"features\"], 15)"
      ],
      "metadata": {
        "id": "GTJSTJ2UYXG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Middle"
      ],
      "metadata": {
        "id": "ay0e9O4TYv21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "\n",
        "def additional_time_features(df):\n",
        "    df['is_night'] = df['hour'].apply(lambda x: 0 <= x <= 4).astype('int8')\n",
        "    df['is_morning_peak'] = df['hour'].apply(lambda x: 6 <= x <= 8).astype('int8')\n",
        "    df['is_evening_peak'] = df['hour'].apply(lambda x: 15 <= x <= 17).astype('int8')\n",
        "    df['weekday'] = df.index.weekday\n",
        "    df['weekend'] = df['weekday'].apply(lambda x: x in (5, 6)).astype('int8')\n",
        "    return df\n",
        "\n",
        "\n",
        "def is_any_holiday(df):\n",
        "    df[\"any_holiday\"] = df[\"is_holiday\"].notna()\n",
        "    df = df.drop(\"is_holiday\", axis=1)\n",
        "    return df\n",
        "\n",
        "\n",
        "def dummy_encoding(df, encoder=None):\n",
        "    ohe_features = [\"weather_type\", \"weather_description\"]\n",
        "    for obj_feature in ohe_features:\n",
        "        df[obj_feature] = df[obj_feature].str.lower().str.replace(\" \", \"_\")\n",
        "\n",
        "    if encoder is None:\n",
        "        encoder = OneHotEncoder(sparse=False, dtype=np.int8, handle_unknown='ignore')\n",
        "        encoded_features = encoder.fit_transform(df[ohe_features])\n",
        "    else:\n",
        "        encoded_features = encoder.transform(df[ohe_features])\n",
        "    \n",
        "    ohe_feature_names = encoder.get_feature_names_out(ohe_features)\n",
        "    df[ohe_feature_names] = encoded_features\n",
        "    df = df.drop(ohe_features, axis=1)\n",
        "    return df, encoder\n",
        "\n",
        "\n",
        "def prepare_data_middle(train_df, val_df):\n",
        "    X_train = train_df.drop([\"traffic_volume\"], axis=1)\n",
        "    X_val = val_df.drop([\"traffic_volume\"], axis=1)\n",
        "\n",
        "    # добавляем временные признаки\n",
        "    X_train = add_time_features(X_train)\n",
        "    X_val = add_time_features(X_val)\n",
        "\n",
        "    # дополнительные признаки периодов дня\n",
        "    X_train = additional_time_features(X_train)\n",
        "    X_val = additional_time_features(X_val)\n",
        "\n",
        "    # работаем с нечисленными признаками\n",
        "    # сделаем бинарный признак праздник / не праздник\n",
        "    X_train = is_any_holiday(X_train)\n",
        "    X_val = is_any_holiday(X_val)\n",
        "\n",
        "    # dummy-кодирование для признаков weather_type, weather_description\n",
        "    X_train, encoder = dummy_encoding(X_train)\n",
        "    X_val, _ = dummy_encoding(X_val, encoder)\n",
        "\n",
        "    # сохраним названия признаков для отрисовки графика\n",
        "    feature_names = X_train.columns.tolist()\n",
        "\n",
        "    y_train = train_df[\"traffic_volume\"]\n",
        "    y_val = val_df[\"traffic_volume\"]\n",
        "\n",
        "    # нормализуем данные для линейной регрессии\n",
        "    scl = MinMaxScaler()\n",
        "    X_train = scl.fit_transform(X_train)\n",
        "    # !Важно: для train применяем метод .fit_transform(), для валидации и/или тест - .transform()\n",
        "    X_val = scl.transform(X_val)\n",
        "    return X_train, y_train, X_val, y_val, feature_names"
      ],
      "metadata": {
        "id": "hHtqDveVbFln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_middle = fit_ridge(train_df, val_df, prepare_data_middle)"
      ],
      "metadata": {
        "id": "rpP66UOtMKlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_preds(val_df[\"traffic_volume\"], result_middle[\"val_preds\"])"
      ],
      "metadata": {
        "id": "-mF5hCG3Zfjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_coefficients(result_middle[\"model\"].coef_, result_middle[\"features\"], 15)"
      ],
      "metadata": {
        "id": "BF8LT-CrF4dG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Senior"
      ],
      "metadata": {
        "id": "mG2RAqKlGNdh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_lags(df, n_lags):\n",
        "    df = df.copy()\n",
        "    for lag_idx in range(1, n_lags + 1):\n",
        "        df[f'lag_{lag_idx}'] = df['traffic_volume'].shift(lag_idx)\n",
        "    df = df.dropna()\n",
        "    return df\n",
        "\n",
        "\n",
        "def cycle_features(df):\n",
        "    df['cos_hour'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
        "    df['sin_hour'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
        "    \n",
        "    df['cos_weekday'] = np.cos(2 * np.pi * df['weekday'] / 7)\n",
        "    df['sin_weekday'] = np.sin(2 * np.pi * df['weekday'] / 7)\n",
        "    \n",
        "    df['cos_month'] = np.cos(2 * np.pi * df['month'] / 12)\n",
        "    df['sin_month'] = np.sin(2 * np.pi * df['month'] / 12)\n",
        "    \n",
        "    df['cos_wind_direction'] = np.cos(2 * np.pi * df['wind_direction'] / 360)\n",
        "    df['sin_wind_direction'] = np.sin(2 * np.pi * df['wind_direction'] / 360)\n",
        "\n",
        "    df = df.drop([\"hour\", \"weekday\", \"month\", \"wind_direction\"], axis=1)\n",
        "    return df\n",
        "\n",
        "\n",
        "def additional_weather_features(df):\n",
        "    df['not_bad_weather'] = df['weather_type_clear'] | df['weather_type_clouds']\n",
        "    df['bad_weather'] = df['weather_type_rain'] | df['weather_type_snow'] | df['weather_type_thunderstorm'] | df['weather_type_squall']\n",
        "    df['doubtful_weather'] = df['weather_type_mist'] | df['weather_type_drizzle'] | df['weather_type_haze'] | df['weather_type_fog']\n",
        "    return df\n",
        "\n",
        "\n",
        "def prepare_data_senior(train_df, val_df):\n",
        "    # добавляем лаги целевой переменной\n",
        "    train_df = add_lags(train_df, n_lags=12)\n",
        "    val_df = add_lags(val_df, n_lags=12)\n",
        "\n",
        "    X_train = train_df.drop([\"traffic_volume\"], axis=1)\n",
        "    X_val = val_df.drop([\"traffic_volume\"], axis=1)\n",
        "\n",
        "    # добавляем временные признаки\n",
        "    X_train = add_time_features(X_train)\n",
        "    X_val = add_time_features(X_val)\n",
        "\n",
        "    # дополнительные признаки периодов дня\n",
        "    X_train = additional_time_features(X_train)\n",
        "    X_val = additional_time_features(X_val)\n",
        "\n",
        "    # циклическое кодирование\n",
        "    X_train = cycle_features(X_train)\n",
        "    X_val = cycle_features(X_val)\n",
        "\n",
        "    # работаем с нечисленными признаками\n",
        "    # сделаем бинарный признак праздник / не праздник\n",
        "    X_train = is_any_holiday(X_train)\n",
        "    X_val = is_any_holiday(X_val)\n",
        "\n",
        "    # dummy-кодирование для признаков weather_type, weather_description\n",
        "    X_train, encoder = dummy_encoding(X_train)\n",
        "    X_val, _ = dummy_encoding(X_val, encoder)\n",
        "\n",
        "    # дополнительные признаки погоды\n",
        "    X_train = additional_weather_features(X_train)\n",
        "    X_val = additional_weather_features(X_val)\n",
        "\n",
        "    # сохраним названия признаков для отрисовки графика\n",
        "    feature_names = X_train.columns.tolist()\n",
        "\n",
        "    y_train = train_df[\"traffic_volume\"]\n",
        "    y_val = val_df[\"traffic_volume\"]\n",
        "\n",
        "    # нормализуем данные для линейной регрессии\n",
        "    scl = MinMaxScaler()\n",
        "    X_train = scl.fit_transform(X_train)\n",
        "    # !Важно: для train применяем метод .fit_transform(), для валидации и/или тест - .transform()\n",
        "    X_val = scl.transform(X_val)\n",
        "    return X_train, y_train, X_val, y_val, feature_names"
      ],
      "metadata": {
        "id": "0LE6BdpxF_zY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_senior = fit_ridge(train_df, val_df, prepare_data_senior)"
      ],
      "metadata": {
        "id": "ruBI_7b1Mh-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_preds(val_df[\"traffic_volume\"], result_senior[\"val_preds\"])"
      ],
      "metadata": {
        "id": "U63pS44VQR4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_coefficients(result_middle[\"model\"].coef_, result_senior[\"features\"], 20)"
      ],
      "metadata": {
        "id": "49pBSQY-QeiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Результаты"
      ],
      "metadata": {
        "id": "DJGS5vmARwlR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.DataFrame({\n",
        "    \"level\": [\"trainee\", \"junior\", \"middle\", \"senior\"],\n",
        "    \"val_mse\": [3947564.7226819396, 3487925.9713073457, 1238385.1927409833, 452914.9664840798]\n",
        "})\n",
        "results[\"val_rmse\"] = np.sqrt(results[\"val_mse\"])\n",
        "results[\"rel_improvement\"] = results[\"val_rmse\"].pct_change() * 100"
      ],
      "metadata": {
        "id": "fwfTbZHoQxnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "id": "gbZElJtSS2Nj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Тест"
      ],
      "metadata": {
        "id": "Thka1BGU-Q3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv(\"indian-metro-test.csv\", parse_dates=[\"date_time\"], index_col=\"date_time\")"
      ],
      "metadata": {
        "id": "PvStzoxp_UIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(train_df, val_df, test_df):\n",
        "    # добавляем лаги целевой переменной\n",
        "    train_df = add_lags(train_df, n_lags=12)\n",
        "    val_df = add_lags(val_df, n_lags=12)\n",
        "    test_df = add_lags(test_df, n_lags=12)\n",
        "\n",
        "    X_train = train_df.drop([\"traffic_volume\"], axis=1)\n",
        "    X_val = val_df.drop([\"traffic_volume\"], axis=1)\n",
        "    X_test = test_df.drop([\"traffic_volume\"], axis=1)\n",
        "\n",
        "    # добавляем временные признаки\n",
        "    X_train = add_time_features(X_train)\n",
        "    X_val = add_time_features(X_val)\n",
        "    X_test = add_time_features(X_test)\n",
        "\n",
        "    # дополнительные признаки периодов дня\n",
        "    X_train = additional_time_features(X_train)\n",
        "    X_val = additional_time_features(X_val)\n",
        "    X_test = additional_time_features(X_test)\n",
        "\n",
        "    # циклическое кодирование\n",
        "    X_train = cycle_features(X_train)\n",
        "    X_val = cycle_features(X_val)\n",
        "    X_test = cycle_features(X_test)\n",
        "\n",
        "    # работаем с нечисленными признаками\n",
        "    # сделаем бинарный признак праздник / не праздник\n",
        "    X_train = is_any_holiday(X_train)\n",
        "    X_val = is_any_holiday(X_val)\n",
        "    X_test = is_any_holiday(X_test)\n",
        "\n",
        "    # dummy-кодирование для признаков weather_type, weather_description\n",
        "    X_train, encoder = dummy_encoding(X_train)\n",
        "    X_val, _ = dummy_encoding(X_val, encoder)\n",
        "    X_test, _ = dummy_encoding(X_test, encoder)\n",
        "\n",
        "    # дополнительные признаки погоды\n",
        "    X_train = additional_weather_features(X_train)\n",
        "    X_val = additional_weather_features(X_val)\n",
        "    X_test = additional_weather_features(X_test)\n",
        "\n",
        "    # сохраним названия признаков для отрисовки графика\n",
        "    feature_names = X_train.columns.tolist()\n",
        "\n",
        "    y_train = train_df[\"traffic_volume\"]\n",
        "    y_val = val_df[\"traffic_volume\"]\n",
        "    y_test = test_df[\"traffic_volume\"]\n",
        "\n",
        "    # нормализуем данные для линейной регрессии\n",
        "    scl = MinMaxScaler()\n",
        "    X_train = scl.fit_transform(X_train)\n",
        "    # !Важно: для train применяем метод .fit_transform(), для валидации и/или тест - .transform()\n",
        "    X_val = scl.transform(X_val)\n",
        "    X_test = scl.transform(X_test)\n",
        "    return X_train, y_train, X_val, y_val, X_test, y_test, feature_names"
      ],
      "metadata": {
        "id": "LPvfp4y-S3P2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train, X_val, y_val, X_test, y_test, feature_names = prepare_data(train_df, val_df, test_df)"
      ],
      "metadata": {
        "id": "1yijnfH3_I3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Ridge(alpha=1.0, random_state=14300631)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "train_predictions = model.predict(X_train)\n",
        "val_predictions = model.predict(X_val)\n",
        "test_predictions = model.predict(X_test)\n",
        "\n",
        "train_mse = mean_squared_error(y_train, train_predictions)\n",
        "val_mse = mean_squared_error(y_val, val_predictions)\n",
        "test_mse = mean_squared_error(y_test, test_predictions)\n",
        "\n",
        "print(f\"Train MSE: {train_mse}\")\n",
        "print(f\"Validation MSE: {val_mse}\")\n",
        "print(f\"Test MSE: {test_mse}\")"
      ],
      "metadata": {
        "id": "JOcxt54R_ciQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_preds(test_df[\"traffic_volume\"], test_predictions)"
      ],
      "metadata": {
        "id": "sotIeoQ4__b4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aGhYhv01AHnJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}